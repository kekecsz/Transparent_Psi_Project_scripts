# This scipt demonstrates that both the t-test and the proportion test
# approaches are vulnerable to bias if only completed sessions are analyzed
# because data can be missing systematically.


############################################
#              Load packages               #
############################################
# BayesFactor package for the bayesian analysis 
library(BayesFactor)


############################################
#         Function for simulation          #
############################################

# function to simulate biased stopping
# this function generates a vector of random biomial numbers where success (1) has a probability defined in "hit_chance".
# if we simulate H0 being true (no precognition), hit_chance is 0.5
# we also have to set the maximum number of trials a person is allowed to carry out, and the minimum number of trials the person will carry out, and the biased stopping rule
# stop_if_result_below defines the stopping rule of the participant. 
# If stop_if_result_below is set to 0.5, it means that the participant will stop if his success rate across all of his own trials is lower than 0.5
# In biased_stopping_chance you can specify the probability of a subject having this biased stopping rule. This can generate a more realistic missing data percentage than simply always stopping when if not winning

biased_sampler <- function(max_trials_per_person,
                           hit_chance,
                           min_trials_per_person,
                           stop_if_result_below,
                           biased_stopping_chance){
  trial_results_vect = NA
  
  if(biased_stopping_chance > runif(n = 1, min = 0, max = 1)){
    for(i in 1:max_trials_per_person){
      trial_results_vect[i] <- rbinom(1, size = 1, prob=hit_chance)
      if((length(trial_results_vect) > (min_trials_per_person-1)) & (mean(trial_results_vect) < stop_if_result_below)) break
    }
  } else {
    trial_results_vect = rbinom(max_trials_per_person, size = 1, prob=hit_chance)
  }
  return(trial_results_vect)
}



############################################
#              Run simulation              #
############################################

# set the number of participants we would like to analyze 
# (note that this refers to the number of participants who finish all 20 trials)

sample_size = 100
max_trials_per_person = 20

# simulate the study
# this loops generates data until we reach the total sample size we pre-specified. 
# Incomplete sessions are not recorded 
# (If the participant did not reach the max_trials_per_person, stopped prematurely because of lower than desired result, that study is not recorded. This is what generates bias here).

trial_results_list = list(NA)

i = 0
repeat{
  i = i + 1
  trial_results_list[[i]] = biased_sampler(max_trials_per_person = max_trials_per_person,
                                           hit_chance = 0.5,
                                           min_trials_per_person = 19, # we set this to 19 so to simulate that participants wait until the penultimate trial to decide whether to drop out or not. This is to simulate deliberate fraud, but this can be decreased to simulate other scenarios, for example people getting fed up by not being able to guess correctly.
                                           stop_if_result_below = 0.5,
                                           # In biased_stopping_chance you can specify the probability of a subject having this biased stopping rule. 
                                           # This can generate a more realistic missing data percentage than simply always stopping when if not winning. 
                                           # If set to 1, this applies to all participants, if set to 0.1 only 10% of the participants 
                                           # consider stopping prematurely because of this bias.
                                           biased_stopping_chance = 1) 
  # this if line makes sure that incomplete sessions are ignored
  if(length(trial_results_list[[i]]) < max_trials_per_person){ i = i - 1}
  if(i == sample_size) break
}


############################################
#           Statistical analysis           #
############################################

# set the null hypothesis success probability, which will be used in the statistical tests
H0_prob = 0.5

# we average successes within each participant. This data will be used in the classical one-sample t-test approach
success_proportions = sapply(trial_results_list, mean)
# run the t-test and extract its p-value
# note that with this extreme stopping rule by the participants
# (stop whenever overall hit rate is abolve p = 0.5 regardless of how many trials the participant did)
# the t-test will always be fooled (as long as the number of trials we analyze reaches around 100)
# this is solely because of the averaging of succeses within participants, which is the data used by the t-test
# so it is not the t-test which is biased, it is the data entered into the t-test that is already biased
t.test(success_proportions, mu = H0_prob, alternative = "greater")$p.value
# this is shown in the mean of the averaged success probabilities
mean(success_proportions)


# the proportion test is ALSO fooled by the biased stopping rule in this case, because it can only see a portion of all trials, 
# and that portion of trials contains a bias.
prop.test(x = sum(unlist(trial_results_list)), n = length(unlist(trial_results_list)), p = H0_prob, alternative = "greater")$p.value
# the raw data where we only pool trials from the completed study sessions is just as biased as the averaged successes within participants
sum(unlist(trial_results_list))/length(unlist(trial_results_list))


# the same goes for the Bayesian proportion test, which will also return a biassed result
bf_proptest_rev = proportionBF(sum(unlist(trial_results_list)), length(unlist(trial_results_list)), p = H0_prob, 
                               rscale = 1/2, nullInterval = c(0.5,1))
BF_proptest <- as.numeric(matrix(1/bf_proptest_rev[1]))
BF_proptest # higher number supports H0
